{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "We pulled data from [here](https://www.kaggle.com/andrewsundberg/college-basketball-dataset/version/4) which has team stats and their success. From this we'll build a model to predict whether a team is in the elite eight by their stats. Finally we'll pull Duke's stats from this year and see what chance they're in the elite eight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        os.path.abspath(\"\"), \"cbb.csv\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TEAM', 'CONF', 'G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
       "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
       "       '3P_D', 'ADJ_T', 'WAB', 'POSTSEASON', 'SEED', 'YEAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"POSTSEASON\"].isin([\"R68\", \"R64\", \"R32\", \"S16\", \"E8\", \"F4\", \"2ND\", \"Champion\"])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEAM          2455\n",
       "CONF          2455\n",
       "G             2455\n",
       "W             2455\n",
       "ADJOE         2455\n",
       "ADJDE         2455\n",
       "BARTHAG       2455\n",
       "EFG_O         2455\n",
       "EFG_D         2455\n",
       "TOR           2455\n",
       "TORD          2455\n",
       "ORB           2455\n",
       "DRB           2455\n",
       "FTR           2455\n",
       "FTRD          2455\n",
       "2P_O          2455\n",
       "2P_D          2455\n",
       "3P_O          2455\n",
       "3P_D          2455\n",
       "ADJ_T         2455\n",
       "WAB           2455\n",
       "POSTSEASON     476\n",
       "SEED           476\n",
       "YEAR          2455\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df[\"POSTSEASON\"].isin([\"Champions\", \"E8\", \"2ND\", \"F4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2399\n",
       "True       56\n",
       "Name: POSTSEASON, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should equal 7 seasons * 8 teams each season\n",
    "targets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(df):\n",
    "    df[\"WINRATIO\"] = df[\"W\"] / df[\"G\"]\n",
    "    means = df.groupby(\"YEAR\").transform(lambda x: x.mean())\n",
    "\n",
    "    fields_to_standardize = [\"ADJOE\", \"ADJDE\", \"BARTHAG\", \"EFG_O\", \"EFG_D\", \"TOR\", \"TORD\", \"ORB\", \"DRB\", \"FTR\", \"FTRD\", \"2P_O\", \"2P_D\", \"3P_O\", \"3P_D\", \"ADJ_T\"]\n",
    "    for field in fields_to_standardize:\n",
    "        df[field] = df[field] / means[field]\n",
    "\n",
    "    return df[[\"WINRATIO\", \"ADJOE\", \"ADJDE\", \"BARTHAG\", \"EFG_O\", \"EFG_D\", \"TOR\", \"TORD\", \"ORB\", \"DRB\", \"FTR\", \"FTRD\", \"2P_O\", \"2P_D\", \"3P_O\", \"3P_D\", \"ADJ_T\", \"WAB\"]]\n",
    "    # return df[[\"WINRATIO\", \"BARTHAG\",\"WAB\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# def get_inputs(df):\n",
    "#     df[\"WINRATIO\"] = df[\"W\"] / df[\"G\"]\n",
    "#     return df[[\"WINRATIO\", \"ADJOE\", \"ADJDE\", \"BARTHAG\", \"EFG_O\", \"EFG_D\", \"TOR\", \"TORD\", \"ORB\", \"DRB\", \"FTR\", \"FTRD\", \"2P_O\", \"2P_D\", \"3P_O\", \"3P_D\", \"ADJ_T\", \"WAB\"]]\n",
    "#     # return df[[\"WINRATIO\", \"BARTHAG\",\"WAB\"]]\n",
    "\n",
    "def preprocess(inputs):\n",
    "    scaler = preprocessing.StandardScaler().fit(inputs)\n",
    "    return scaler.transform(inputs)\n",
    "\n",
    "def build_and_test_model(test_validation_ratio=0.75):\n",
    "    inputs = get_inputs(df)\n",
    "\n",
    "\n",
    "    scaled_inputs = preprocess(inputs)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_inputs, targets, test_size=1 - test_validation_ratio, random_state=42)\n",
    "\n",
    "    w = [{0:1000,1:100},{0:1000,1:10}, {0:1000,1:1.0}, \n",
    "        {0:500,1:1.0}, {0:400,1:1.0}, {0:300,1:1.0}, {0:200,1:1.0}, \n",
    "        {0:150,1:1.0}, {0:100,1:1.0}, {0:99,1:1.0}, {0:10,1:1.0}, \n",
    "        {0:0.01,1:1.0}, {0:0.01,1:10}, {0:0.01,1:100}, \n",
    "        {0:0.001,1:1.0}, {0:0.005,1:1.0}, {0:1.0,1:1.0}, \n",
    "        {0:1.0,1:0.1}, {0:10,1:0.1}, {0:100,1:0.1}, \n",
    "        {0:10,1:0.01}, {0:1.0,1:0.01}, {0:1.0,1:0.001}, {0:1.0,1:0.005}, \n",
    "        {0:1.0,1:10}, {0:1.0,1:99}, {0:1.0,1:100}, {0:1.0,1:150}, \n",
    "        {0:1.0,1:200}, {0:1.0,1:300},{0:1.0,1:400},{0:1.0,1:500}, \n",
    "        {0:1.0,1:1000}, {0:10,1:1000},{0:100,1:1000} ]\n",
    "    crange = np.arange(1, 20.0, 2)\n",
    "    hyperparam_grid = {\"class_weight\": w\n",
    "                    ,\"penalty\": [None, \"l1\", \"l2\"]\n",
    "                    ,\"C\": crange\n",
    "                    ,\"fit_intercept\": [True, False]  }\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    grid = GridSearchCV(log_reg,hyperparam_grid,scoring=\"roc_auc\", cv=None, n_jobs=-1, refit=True)\n",
    "    grid.fit(scaled_inputs, targets)\n",
    "    print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')\n",
    "    # if test_validation_ratio < 1:\n",
    "    #     print(f\"Accuracy: {accuracy_score(y_test, log_reg.predict(X_test))}\")\n",
    "    #     print(f\"Confusion Matrix: {confusion_matrix(y_test, log_reg.predict(X_test))}\")\n",
    "    #     print(f\"ROC-AUC: {roc_auc_score(y_test, log_reg.predict(X_test))}\")\n",
    "    #     print(f\"Recall: {recall_score(y_test, log_reg.predict(X_test))}\")\n",
    "    #     print(f\"Random Accuracy: {accuracy_score(y_test, [random.randint(1, 8) == 1 for row in y_test])}\")\n",
    "\n",
    "    best_reg = LogisticRegression(max_iter=1000, **grid.best_params_)\n",
    "    best_reg.fit(scaled_inputs, targets)\n",
    "    return best_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_272141/2889140168.py:3: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the transforming function.\n",
      "  means = df.groupby(\"YEAR\").transform(lambda x: x.mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9766032453976088 with param: {'C': 3.0, 'class_weight': {0: 0.001, 1: 1.0}, 'fit_intercept': False, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7000 fits failed out of a total of 10500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mark/.cache/pypoetry/virtualenvs/predictingtheorb-I8IAuHj--py3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.97212738 ...        nan        nan 0.94265768]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "regression = build_and_test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duke 2022 -- Elite 8 chance: 33.49%\n",
      "Louisville 2013 -- Elite 8 chance: 52.2%\n",
      "Connecticut 2014 -- Elite 8 chance: 17.75%\n",
      "Duke 2015 -- Elite 8 chance: 66.72%\n",
      "Villanova 2016 -- Elite 8 chance: 51.46%\n",
      "North Carolina 2017 -- Elite 8 chance: 44.42%\n",
      "Villanova 2018 -- Elite 8 chance: 66.32%\n",
      "Virginia 2019 -- Elite 8 chance: 71.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_272141/2889140168.py:3: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the transforming function.\n",
      "  means = df.groupby(\"YEAR\").transform(lambda x: x.mean())\n"
     ]
    }
   ],
   "source": [
    "duke_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        os.path.abspath(\"\"), \"duke.csv\"\n",
    "    )\n",
    ")\n",
    "\n",
    "inputs = get_inputs(duke_df)\n",
    "\n",
    "\n",
    "scaled_inputs = preprocess(inputs)\n",
    "\n",
    "probabilities = regression.predict_proba(scaled_inputs)\n",
    "\n",
    "for i, p in enumerate(probabilities):\n",
    "    print(f\"{duke_df.loc[i, 'TEAM']} {duke_df.loc[i, 'YEAR']} -- Elite 8 chance: {round(p[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "According to our model, we predict the following:\n",
    "\n",
    "Duke 2022 -- Elite 8 chance: 33.49%\n",
    "\n",
    "We also computed previous champions elite 8 chances to sanity check our model.\n",
    "\n",
    "I've copied 538's model results for Elite 8 chances for each of these teams as well for comparison\n",
    "\n",
    "| Team | Year | Predicted Chance | 538 Chance |\n",
    "| --- | ----------- | --- | ----------- |\n",
    "| Louisville | 2013 | 52.2% | NA - No model this year |\n",
    "| Connecticut | 2014 | 17.75% | 14% |\n",
    "| Duke | 2015 | 66.72% | 55% |\n",
    "| Villanova | 2016 | 51.46% | 47% |\n",
    "| North Carolina | 2017 | 44.42% | 58% |\n",
    "| Villanova | 2018 | 66.32% | 67% |\n",
    "| Virginia | 2019 | 71.58% | 73% |\n",
    "\n",
    "Our percent chances agree very closely with 538's. Given that I think we should use our numbers with slight adjustments.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a04380b1b5c996b865d83f234604541c218d018d91e0035bb1e0c4b6061d90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('predictingtheorb-I8IAuHj--py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
